{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt1 은 주어진 주제에 대한 짧은 설명을, prompt2 는 영어로 번역해 달라는 요청 프롬프트 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} 에 대해 짧게 한글로 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} 를 emoji를 활용한 인스타그램 게시글로 만들어주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=key, \n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @chain 데코레이터로 사용자 정의 함수를 데코레이팅 하며, 데코레이팅을 통해 함수를 Runnable 한 객체로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    chain1 = prompt1 | llm | output_parser \n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    chain2 = prompt2 | llm | output_parser    \n",
    "    return chain2.invoke({\"sentence\": output1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌟 **랭체인(Chain of Thought)** 🌟\n",
      "\n",
      "🤖 인공지능 모델이 문제를 해결할 때, 사고 과정을 단계적으로 표현하는 방법! 🧠✨\n",
      "\n",
      "🔍 이 접근 방식은 모델이 문제를 해결하는 데 필요한 논리적 단계를 명확히 하여, 더 나은 결과를 도출할 수 있도록 돕습니다. 💡💪\n",
      "\n",
      "🧩 특히 복잡한 문제 해결이나 추론 작업에서 효과적이며, 모델의 이해도를 높이는 데 기여합니다! 🚀📈\n",
      "\n",
      "#랭체인 #ChainOfThought #AI #인공지능 #문제해결 #논리적사고 #추론 #기술혁신 #미래기술\n"
     ]
    }
   ],
   "source": [
    "# custom_chain은 이제 실행 가능한 객체(runnable)이므로, invoke() 를 사용하여 실행해야 합니다.\n",
    "print(custom_chain.invoke(\"랭체인\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
