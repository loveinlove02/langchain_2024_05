{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt1 ì€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•œ ì§§ì€ ì„¤ëª…ì„, prompt2 ëŠ” ì˜ì–´ë¡œ ë²ˆì—­í•´ ë‹¬ë¼ëŠ” ìš”ì²­ í”„ë¡¬í”„íŠ¸ ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ì§§ê²Œ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} ë¥¼ emojië¥¼ í™œìš©í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œê¸€ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=key, \n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @chain ë°ì½”ë ˆì´í„°ë¡œ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ë°ì½”ë ˆì´íŒ… í•˜ë©°, ë°ì½”ë ˆì´íŒ…ì„ í†µí•´ í•¨ìˆ˜ë¥¼ Runnable í•œ ê°ì²´ë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    chain1 = prompt1 | llm | output_parser \n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    chain2 = prompt2 | llm | output_parser    \n",
    "    return chain2.invoke({\"sentence\": output1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒŸ **ë­ì²´ì¸(Chain of Thought)** ğŸŒŸ\n",
      "\n",
      "ğŸ¤– ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ, ì‚¬ê³  ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•! ğŸ§ âœ¨\n",
      "\n",
      "ğŸ” ì´ ì ‘ê·¼ ë°©ì‹ì€ ëª¨ë¸ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° í•„ìš”í•œ ë…¼ë¦¬ì  ë‹¨ê³„ë¥¼ ëª…í™•íˆ í•˜ì—¬, ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. ğŸ’¡ğŸ’ª\n",
      "\n",
      "ğŸ§© íŠ¹íˆ ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì´ë‚˜ ì¶”ë¡  ì‘ì—…ì—ì„œ íš¨ê³¼ì ì´ë©°, ëª¨ë¸ì˜ ì´í•´ë„ë¥¼ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤! ğŸš€ğŸ“ˆ\n",
      "\n",
      "#ë­ì²´ì¸ #ChainOfThought #AI #ì¸ê³µì§€ëŠ¥ #ë¬¸ì œí•´ê²° #ë…¼ë¦¬ì ì‚¬ê³  #ì¶”ë¡  #ê¸°ìˆ í˜ì‹  #ë¯¸ë˜ê¸°ìˆ \n"
     ]
    }
   ],
   "source": [
    "# custom_chainì€ ì´ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´(runnable)ì´ë¯€ë¡œ, invoke() ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "print(custom_chain.invoke(\"ë­ì²´ì¸\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
