{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt1 은 주어진 주제에 대한 짧은 설명을, prompt2 는 영어로 번역해 달라는 요청 프롬프트 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} 에 대해 짧게 한글로 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} 를 emoji를 활용한 인스타그램 게시글로 만들어주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=key, \n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @chain 데코레이터로 사용자 정의 함수를 데코레이팅 하며, 데코레이팅을 통해 함수를 Runnable 한 객체로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    chain1 = prompt1 | llm | output_parser \n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    chain2 = prompt2 | llm | output_parser    \n",
    "    return chain2.invoke({\"sentence\": output1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌟 **랭체인(LLM Chain)** 🌟\n",
      "\n",
      "대규모 언어 모델(LLM)을 활용하여 다양한 애플리케이션을 쉽게 구축하고 운영할 수 있는 프레임워크! 🚀✨\n",
      "\n",
      "이제 언어 모델을 사용한 데이터 처리, API 호출, 사용자 인터페이스 통합이 간편해졌어요! 💻🔗 개발자 여러분, 복잡한 작업을 간소화하고 효율적으로 작업해보세요! 💪\n",
      "\n",
      "자연어 처리(NLP)와 관련된 다양한 기능을 제공하여, 챗봇 🤖, 자동화된 콘텐츠 생성 ✍️, 데이터 분석 📊 등 여러 분야에서 활용할 수 있습니다!\n",
      "\n",
      "#랭체인 #LLMChain #자연어처리 #AI #챗봇 #콘텐츠생성 #데이터분석 #프레임워크 #개발자 #혁신 #기술\n"
     ]
    }
   ],
   "source": [
    "# custom_chain은 이제 실행 가능한 객체(runnable)이므로, invoke() 를 사용하여 실행해야 합니다.\n",
    "print(custom_chain.invoke(\"랭체인\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
