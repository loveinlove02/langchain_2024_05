{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization\n",
    "# Stuff: 전체 문서 한 번에 요약.\n",
    "#        단순히 모든 문서를 단일 프롬프트로 \"넣는\" 방법. 이는 가장 간단한 접근 방식입니다.\n",
    "\n",
    "# stuff documents chain은 문서 체인 중 가장 간단한 방식입니다. \n",
    "# 문서 목록을 가져와서 모두 프롬프트에 삽입한 다음, 그 프롬프트를 LLM에 전달합니다.\n",
    "# 이 체인은 문서가 작고 대부분의 호출에 몇 개만 전달되는 애플리케이션에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스데이터 로드\n",
    "loader = TextLoader(\"./data/news.txt\", encoding='utf-8')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 글자수: 1708\n"
     ]
    }
   ],
   "source": [
    "print(f\"총 글자수: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= 앞부분 미리보기 =========\n",
      "\n",
      "제목: \n",
      "AI2, 상업 활용까지 자유로운 '진짜' 오픈 소스 LLM '올모' 출시\n",
      "\n",
      "내용:\n",
      "앨런AI연구소(AI2)가 완전한 오픈 소스 대형언어모델(LLM) '올모(OLMo)’를 출시했다. 데이터 수집, 학습, 배포의 전 과정을 투명하게 공개한 데다 상업적 사용까지 허용한 진정한 의미의 오픈 소스 LLM이라는 평가다.\n",
      "벤처비트는 1일(현지시간) 비영리 민간 AI 연구기관인 AI2가 ‘최초의 진정한 오픈 소스 LLM 및 프레임워크’라고 소개한 ‘올모’를 출시했다고 보도했다. \n",
      "이에 따르면 올모는 모델 코드와 모델 가중치뿐만 아니라 훈련 코드, 훈련 데이터, 관련 툴킷 및 평가 툴킷도 제공한다. 이를 통해 모델이 어떻게 구축되었는지 심층적으로 분석, LLM의 작동 방식과 응답을 생성하는 원리를 더 잘 이해할 수 있다. \n",
      "올모 프레임워크는 70억 매개변수의 ‘올모 7B’ 등 4가지 변형 모델과 10억 매개변수의 ‘올모 1B’ 모델을 제공한다. 모델들은 훈련 데이터를 생성하는 코드를 포함해 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========= 앞부분 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please summarize the sentence according to the following REQUEST.\n",
      "REQUEST:\n",
      "1. Summarize the main points in bullet points in KOREAN.\n",
      "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
      "3. Use various emojis to make the summary more interesting.\n",
      "4. Translate the summary into KOREAN if it is written in ENGLISH.\n",
      "5. DO NOT translate any technical terms.\n",
      "6. DO NOT include any unnecessary information.\n",
      "\n",
      "CONTEXT:\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "SUMMARY:\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 한국어로 요약을 작성하라는 문구가 추가된 prompt 입니다.\n",
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_teddynote.callbacks import StreamingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=key, \n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.1, \n",
    "    streaming=True,\n",
    "    callbacks=[StreamingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 🚀 앨런AI연구소(AI2)가 완전한 오픈 소스 LLM '올모(OLMo)'를 출시했다.  \n",
      "- 📊 데이터 수집, 학습, 배포 과정을 투명하게 공개하고 상업적 사용을 허용한다.  \n",
      "- 🔍 올모는 모델 코드, 가중치, 훈련 코드, 데이터 및 평가 툴킷을 제공한다.  \n",
      "- 🧠 70억 매개변수의 '올모 7B'와 10억 매개변수의 '올모 1B' 모델을 포함한 4가지 변형 모델이 있다.  \n",
      "- 📈 훈련 데이터는 3조개의 토큰으로 구성된 AI2의 '돌마(Dolma)' 데이터 세트를 기반으로 한다.  \n",
      "- 📝 아파치 2.0 라이선스에 따라 상업적 활용에 제한이 없다.  \n",
      "- 💬 AI2의 프로젝트 책임자는 투명성이 부족한 현재의 언어 모델에 대한 문제를 지적했다.  \n",
      "- 🌟 올모는 상업용 제품과 동등한 성능을 보여주며, 일부 벤치마크에서 우수한 성과를 기록했다.  \n",
      "- ⚠️ 비영어권 언어와 코드 생성 기능에 대한 제약이 있다.  \n",
      "- 🔧 AI2는 올모를 지속적으로 개선할 계획이다.  \n",
      "- 🌐 모든 리소스는 깃허브 및 허깅페이스에서 무료로 제공된다.  "
     ]
    }
   ],
   "source": [
    "answer = stuff_chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = ChatOpenAI(\n",
    "    api_key=key, \n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0,\n",
    "    callbacks=[StreamingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_chain2 = create_stuff_documents_chain(llm2, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = stuff_chain2.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 🚀 앨런AI연구소(AI2)가 완전한 오픈 소스 LLM '올모(OLMo)'를 출시했다.  \n",
      "- 🔍 데이터 수집, 학습, 배포 과정을 투명하게 공개하고 상업적 사용을 허용한다.  \n",
      "- 📊 올모는 모델 코드, 가중치, 훈련 코드, 데이터 및 평가 툴킷을 제공한다.  \n",
      "- 🧩 70억 매개변수의 '올모 7B'와 10억 매개변수의 '올모 1B' 모델을 포함한 4가지 변형 모델이 있다.  \n",
      "- 📈 AI2의 '돌마(Dolma)' 데이터 세트를 기반으로 3조개의 토큰으로 사전 훈련되었다.  \n",
      "- 📜 아파치 2.0 라이선스에 따라 상업적 활용에 제한이 없다.  \n",
      "- 🧪 올모는 상업용 제품과 동등한 성능을 보여주며, 일부 벤치마크 테스트에서 우수한 성과를 기록했다.  \n",
      "- 🌍 비영어권 언어에 대한 낮은 품질과 약한 코드 생성 기능이 제약 사항으로 지적되었다.  \n",
      "- 🔧 AI2는 올모를 계속해서 향상할 계획이다.  \n",
      "- 🌐 현재 올모의 모든 리소스는 깃허브 및 허깅페이스에서 무료로 제공된다.  \n"
     ]
    }
   ],
   "source": [
    "print(answer2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
