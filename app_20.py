import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage
from dotenv import load_dotenv
import os

load_dotenv(verbose=True)
key = os.getenv('OPENAI_API_KEY')

st.title('chatGPT ğŸ’¬')

if 'messages' not in st.session_state:
    st.session_state['messages'] = []


def add_message(role, message):  # ë¡¤(user, assistant), ë©”ì‹œì§€(ì§ˆë¬¸, ë‹µë³€)
    st.session_state['messages'].append(
        ChatMessage(role=role, content=message)
    )

def print_messages():
    for chat_message in st.session_state['messages']:
        with st.chat_message(chat_message.role):
            st.write(chat_message.content)

def create_chain():
    prompt = ChatPromptTemplate.from_messages(
        [
            ('system', 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì´ìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤.'), 
            ('user', '#Question:\n{question}')
        ]
    )

    llm = ChatOpenAI(
        api_key=key, 
        model_name='gpt-4o-mini', 
        temperature=0
    )

    output_parser = StrOutputParser()

    chain = prompt | llm | output_parser
    return chain

print_messages()

user_input = st.chat_input('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?')

if user_input:
    with st.chat_message('user'):
        st.write(user_input)

    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•  chain
    chain = create_chain()

    # chainì— ì§ˆë¬¼ì„ ë˜ì ¸ì„œ ë‹µë³€ì–»ê¸°(answer)
    answer = chain.invoke({'question': user_input})

    with st.chat_message('assistant'):
        st.write(answer)
    
    add_message('user', user_input)
    add_message('assistant', answer)

